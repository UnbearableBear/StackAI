{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# One Knowledge Base to Rule Them All Workflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "\n",
    "def get_auth_headers(email: str, password: str) -> dict[str, str]:\n",
    "    \"\"\"Get auth headers for the selected user.\"\"\"\n",
    "    supabase_auth_url = \"https://sb.stack-ai.com\"\n",
    "    anon_key = \"eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJzdXBhYmFzZSIsInJlZiI6ImZic3VhZGZxaGtseG9rbWxodHNkIiwicm9sZSI6ImFub24iLCJpYXQiOjE2NzM0NTg5ODAsImV4cCI6MTk4OTAzNDk4MH0.Xjry9m7oc42_MsLRc1bZhTTzip3srDjJ6fJMkwhXQ9s\"\n",
    "\n",
    "    request_url = f\"{supabase_auth_url}/auth/v1/token?grant_type=password\"\n",
    "    response = requests.post(\n",
    "        request_url,\n",
    "        json={\n",
    "            \"email\": email,\n",
    "            \"password\": password,\n",
    "            \"gotrue_meta_security\": {},\n",
    "        },\n",
    "        headers={\n",
    "            \"Content-Type\": \"application/json\",\n",
    "            \"Apikey\": anon_key,\n",
    "        },\n",
    "        timeout=10,\n",
    "    )\n",
    "    response.raise_for_status()\n",
    "    access_token = response.json()[\"access_token\"]\n",
    "\n",
    "    headers = {\"Authorization\": f\"Bearer {access_token}\"}\n",
    "\n",
    "    return headers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Login to your account to get your auth headers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "email = \"stackaitest@gmail.com\"\n",
    "password = input(f\"Introduce the password for {email}: \")\n",
    "\n",
    "auth_headers = get_auth_headers(email, password)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a request session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "session = requests.Session()\n",
    "\n",
    "session.headers.update(auth_headers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set the correct url for the backend you want to use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "backend_url = \"https://api.stack-ai.com\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "org_id = session.get(f\"{backend_url}/organizations/me/current\").json()[\"org_id\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Connections"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Create a Google Drive connection in the Stack AI Workflow builder\n",
    "\n",
    "1. Go to the Stack AI Workflow builder\n",
    "2. On the left sidebar, click on Knowledge Bases\n",
    "3. Drop the Google Drive node on the canvas\n",
    "4. Click on connect to Google Drive on the node and follow the authorization steps."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 List all the connections for the selected user\n",
    "\n",
    "\n",
    "Your newly created connection will be listed here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "connection_list_url = f\"{backend_url}/connections?connection_provider=gdrive&limit=1\"\n",
    "resource = session.get(connection_list_url)\n",
    "\n",
    "resource.raise_for_status()\n",
    "\n",
    "connection = resource.json()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Connection information:\")\n",
    "print(\"----------------------\")\n",
    "print(f\"Connection ID: {connection['connection_id']}\")\n",
    "print(f\"Connection name: {connection['name']}\")\n",
    "print(f\"Created at: {connection['created_at']}\")\n",
    "print(f\"Updated at: {connection['updated_at']}\")\n",
    "\n",
    "# Commented to avoid leaking sensitive information\n",
    "# print(f\"Connection provider: {connection['connection_provider_data']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 List available resources under the connection\n",
    "\n",
    "\n",
    ":warning: The responses from this endpoint are paginated! :warning:\n",
    "\n",
    "The response has the following fields:\n",
    "- `data`: `list[T]` A list of resources.\n",
    "- `next_cursor`: `str | None` The cursor to use to fetch the next page of resources if there is one.\n",
    "- `current_cursor`: `str | None` The cursor to use to re-fetch the current page of resources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "connection_id = connection[\"connection_id\"]\n",
    "connection_resources_url = f\"{backend_url}/connections/{connection_id}/resources\"\n",
    "children_resources_url = f\"{backend_url}/connections/{connection_id}/resources/children\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Root resources** \n",
    "\n",
    "Lets start with the root resources, to do it, we should not specify a path, so we will get all the resources in the connection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Pinging: \", children_resources_url)\n",
    "root_resources_response = session.get(children_resources_url)\n",
    "\n",
    "root_resources_response.raise_for_status()\n",
    "\n",
    "root_resources = root_resources_response.json()\n",
    "\n",
    "for resource in root_resources['data']:\n",
    "    emoji = \"üìÅ\" if resource[\"inode_type\"] == \"directory\" else \"üìÑ\"\n",
    "\n",
    "    print(f\"{emoji} {resource['inode_path']['path']:30} (resource_id: {resource['resource_id']})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Lets take a look at the raw response from the API**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for resource in root_resources['data']:\n",
    "    print(resource)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from urllib.parse import urlencode\n",
    "\n",
    "\n",
    "def get_specific_file(resource_id: str, resources_url: str) -> None:\n",
    "    data = {\"resource_id\": resource_id}\n",
    "\n",
    "    # Encode the query parameters\n",
    "    encoded_query_params = urlencode(data, doseq=True)\n",
    "    url = f\"{resources_url}?{encoded_query_params}\"\n",
    "\n",
    "    print(\"Pinging: \", url)\n",
    "    response = session.get(url)\n",
    "\n",
    "    response.raise_for_status()\n",
    "\n",
    "    resources = response.json().get(\"data\", [])\n",
    "\n",
    "    if len(resources) == 0:\n",
    "        print(\"No resources found\")\n",
    "        return\n",
    "\n",
    "    if isinstance(resources, dict):\n",
    "        resources = [resources]\n",
    "\n",
    "    for response in resources:\n",
    "        emoji = \"üìÅ\" if response[\"inode_type\"] == \"directory\" else \"üìÑ\"\n",
    "        print(f\"{emoji} {response['inode_path']['path']:30} (resource_id: {response['resource_id']})\")\n",
    "\n",
    "    print(\"\\n\\nRaw response:\")\n",
    "    print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Get the resources in a directory, like Papers**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the resource_id of the folder 'papers'.\n",
    "# Replace it with the resource_id of the file you want to get the information from.\n",
    "resource_id = \"1YeS8H92ZmTZ3r2tLn1m43GG58gRzvYiM\"\n",
    "get_specific_file(resource_id=resource_id, resources_url=children_resources_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Get the resources in a directory, like papers/another folder (nested)**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resource_id = \"1Qxd08BxFKH0vWdTRnbrA2ncSvUR7CKzH\"\n",
    "get_specific_file(resource_id=resource_id, resources_url=children_resources_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Knowledge Bases\n",
    "\n",
    "Once the user has decided which resources they want to index, they can create a knowledge base. A knowledge base is a collection of resources that are indexed in our vector database. \n",
    "\n",
    "\n",
    "In this example, we will suppose that the user has decided to index the following resources:\n",
    "- üìÅ papers                         (resource_id: 17nmGKUBjR_djw4SHiEMqmqb67vAH1uST)\n",
    "- üìÑ Very Important notes.txt       (resource_id: 1wWBg9mJkWFJUbEdRjjjkX4jf7TYmE__GRRfAjSh6fzs)\n",
    "\n",
    "\n",
    "This means that `papers` and all of its subfolders will be indexed as well as the `manu_document_awesome.txt` file will be indexed.\n",
    "\n",
    "It is important that the frontend contains logic to avoid passing both a resource and its children in the list of resources to be indexed. For example, if the frontend passses both\n",
    "- üìÅ test_folder                    (resource_id: 1cGeHFazvfHDSOfDJ_SRZEzkm5q1-Zn41)\n",
    "- üìÑ test_folder/test_file.pdf (resource_id: 18nr8ZUE0QQZgNITw1JeEV1ZaobMDxUNC)\n",
    "\n",
    "While the backend will work fine and index everything under `test_folder`, there will be duplicate work to get the metadata of the `test_file.pdf` file both as a child of `test_folder` and as an independent resource."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Creating a knowledge base\n",
    "Lets create a knowledge base that will be synced to the selected resources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "create_kb_url = f\"{backend_url}/knowledge_bases\"\n",
    "\n",
    "\n",
    "connection_source_ids = [\n",
    "    \"1YeS8H92ZmTZ3r2tLn1m43GG58gRzvYiM\",  # The Papers folder\n",
    "    \"1GYpHUOiSYXGz_9GeUGgQkwQUJqCAxibGd9szwMJQSIg\",  # Very Important notes.txt file\n",
    "]\n",
    "\n",
    "\n",
    "data = {\n",
    "    \"connection_id\": connection_id,\n",
    "    \"connection_source_ids\": connection_source_ids,\n",
    "    \"indexing_params\": {\n",
    "        \"ocr\": False,\n",
    "        \"unstructured\": True,\n",
    "        \"embedding_params\": {\"embedding_model\": \"text-embedding-ada-002\", \"api_key\": None},\n",
    "        \"chunker_params\": {\"chunk_size\": 1500, \"chunk_overlap\": 500, \"chunker\": \"sentence\"},\n",
    "    },\n",
    "    \"org_level_role\": None,\n",
    "    \"cron_job_id\": None,\n",
    "}\n",
    "\n",
    "print(\"Pinging: \", create_kb_url)\n",
    "kb_create_response = session.post(create_kb_url, data=json.dumps(data))\n",
    "\n",
    "new_kb_json = kb_create_response.json()\n",
    "print(new_kb_json)\n",
    "\n",
    "knowledge_base_id = new_kb_json[\"knowledge_base_id\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Sync Knowledge Base\n",
    "\n",
    "To load the resources from the connection into the knowledge base, we need to call the `sync` endpoint of the knowledge base. The syncing will be done on a background task, so we need to wait for the task to finish before we can access the resources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kb_sync_url = f\"{backend_url}/knowledge_bases/sync/trigger/{knowledge_base_id}/{org_id}\"\n",
    "\n",
    "print(\"Pinging: \", kb_sync_url)\n",
    "sync_response = session.get(kb_sync_url)\n",
    "\n",
    "print(sync_response.status_code)\n",
    "print(sync_response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 Get the list of files in the knowledge base\n",
    "\n",
    "At first, the files will be in the pending state as their indexing is not yet complete. If you wait for about a minute, you should see the files in the indexed state.\n",
    "\n",
    "\n",
    ":warning: The responses from this endpoint are paginated! :warning:\n",
    "\n",
    "The response has the following fields:\n",
    "- `data`: `list[T]` A list of resources.\n",
    "- `next_cursor`: `str | None` The cursor to use to fetch the next page of resources if there is one.\n",
    "- `current_cursor`: `str | None` The cursor to use to re-fetch the current page of resources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_kb_resources(data: dict, knowledge_base_id: str) -> None:\n",
    "    kb_children_resources_url = f\"{backend_url}/knowledge_bases/{knowledge_base_id}/resources/children\"\n",
    "\n",
    "    encoded_query_params = urlencode(data)\n",
    "    url = f\"{kb_children_resources_url}?{encoded_query_params}\"\n",
    "    print(\"Pinging: \", url)\n",
    "    response = session.get(url, data=json.dumps(data))\n",
    "\n",
    "    response.raise_for_status()\n",
    "\n",
    "    resources = response.json().get(\"data\", [])\n",
    "\n",
    "    if len(resources) == 0:\n",
    "        print(\"No resources found\")\n",
    "\n",
    "    if isinstance(resources, dict):\n",
    "        resources = [resources]\n",
    "\n",
    "    for resource in resources:\n",
    "        emoji = \"üìÅ\" if resource[\"inode_type\"] == \"directory\" else \"üìÑ\"\n",
    "        print(\n",
    "            f\"{emoji} {resource['inode_path']['path']:30} (resource_id: {resource['resource_id']}) status: {resource.get('status')}\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = { \"resource_path\": \"/\", }\n",
    "print_kb_resources(data, knowledge_base_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\n",
    "    \"resource_path\": \"/papers\",\n",
    "}\n",
    "print_kb_resources(data, knowledge_base_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\n",
    "    \"resource_path\": \"papers/another folder\",\n",
    "}\n",
    "print_kb_resources(data, knowledge_base_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4 Manually manipulate the knowledge base"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Delete a file\n",
    "For now, only files can be deleted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kb_children_resources_url = f\"{backend_url}/knowledge_bases/{knowledge_base_id}/resources\"\n",
    "\n",
    "data = {\n",
    "    \"resource_path\": \"papers/self_rag.pdf\",\n",
    "}\n",
    "encoded_query_params = urlencode(data)\n",
    "resource = session.delete(\n",
    "    f\"{kb_children_resources_url}?{encoded_query_params}\",\n",
    "    data=json.dumps(data),\n",
    ")\n",
    "\n",
    "\n",
    "print(resource.status_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "# Wait for the deletion to finish\n",
    "time.sleep(5)\n",
    "\n",
    "data = {\n",
    "    \"resource_path\": \"papers/\",\n",
    "}\n",
    "print_kb_resources(data, knowledge_base_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a file\n",
    "For now, only files can be created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the metadata and file content\n",
    "create_request_metadata = {\n",
    "        \"resource_type\": \"file\",\n",
    "        \"resource_path\": \"papers/papers/demo_file.txt\",\n",
    "}\n",
    "file_content = b\"test file content\"\n",
    "\n",
    "# Prepare the files dictionary\n",
    "files = {\n",
    "    \"file\": (\"file.txt\", file_content, \"text/plain\"),\n",
    "}\n",
    "\n",
    "# Make the POST request\n",
    "resource = session.post(\n",
    "    f\"{backend_url}/knowledge_bases/{knowledge_base_id}/resources\",\n",
    "    files=files,\n",
    "    data=create_request_metadata,  # Use data instead of json for multipart form-data\n",
    ")\n",
    "\n",
    "print(resource.status_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "time.sleep(5)\n",
    "\n",
    "data = {\n",
    "    \"resource_path\": \"papers/papers/\",\n",
    "}\n",
    "print_kb_resources(data, knowledge_base_id)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
